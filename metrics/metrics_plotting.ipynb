{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X_ZK4hiwjuIG",
        "outputId": "80291f06-db6e-4338-ec6e-102dd9c70611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MMML-Group-Project'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 137 (delta 68), reused 71 (delta 24), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (137/137), 4.10 MiB | 23.85 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Frostday/MMML-Group-Project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qyl7ktmoj3wP",
        "outputId": "ac8d118a-9d83-46af-e203-438d3211d5c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.50.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.29.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
            "Collecting git+https://github.com/salaniz/pycocoevalcap\n",
            "  Cloning https://github.com/salaniz/pycocoevalcap to /tmp/pip-req-build-v86hoyy8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/salaniz/pycocoevalcap /tmp/pip-req-build-v86hoyy8\n",
            "  Resolved https://github.com/salaniz/pycocoevalcap to commit a24f74c408c918f1f4ec34e9514bc8a76ce41ffd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from pycocoevalcap==1.2) (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.17.0)\n",
            "Building wheels for collected packages: pycocoevalcap\n",
            "  Building wheel for pycocoevalcap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocoevalcap: filename=pycocoevalcap-1.2-py3-none-any.whl size=104312245 sha256=b0dca34e48a2dad2c239fa82a14f9c65d7a125668e960fec145854b8010eebfa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4ca729x8/wheels/d2/1f/44/6485e566f8ae3d42b56e7c05fd50a3bbb70a50b0e6e7c55212\n",
            "Successfully built pycocoevalcap\n",
            "Installing collected packages: pycocoevalcap\n",
            "Successfully installed pycocoevalcap-1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install bert-score\n",
        "!pip install git+https://github.com/salaniz/pycocoevalcap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KFFyQVkPjgpM",
        "outputId": "0adeeb22-38d4-4ec9-f357-dd1252cec6c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 222kB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 2.53MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.88MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 9.86MB/s]\n",
            "2025-03-25 23:11:19.615221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742944279.954278    2845 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742944280.054887    2845 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-25 23:11:20.801068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 440M/440M [00:03<00:00, 127MB/s] \n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "\n",
            "📄 Evaluating CSV: /content/MMML-Group-Project/data/blip2_results.csv (model: resnet_mlp)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 18943 tokens at 35491.02 tokens per second.\n",
            "PTBTokenizer tokenized 8568 tokens at 35187.82 tokens per second.\n",
            "setting up scorers...\n",
            "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
            "Progress: 384.5M / 384.5M (100.0%)\n",
            "Extracting stanford-corenlp-3.6.0 ...\n",
            "Done.\n",
            "computing Bleu score...\n",
            "{'testlen': 7682, 'reflen': 16605, 'guess': [7682, 7105, 6626, 6185], 'correct': [3704, 2123, 1440, 961]}\n",
            "ratio: 0.46263173742845753\n",
            "Bleu_1: 0.151\n",
            "Bleu_2: 0.119\n",
            "Bleu_3: 0.099\n",
            "Bleu_4: 0.083\n",
            "computing METEOR score...\n",
            "METEOR: 0.118\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.242\n",
            "computing CIDEr score...\n",
            "CIDEr: 0.890\n",
            "computing SPICE score...\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
            "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Parsing reference captions\n",
            "Initiating Stanford parsing pipeline\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
            "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
            "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
            "done [1.2 sec].\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.5 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.0 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.3 sec].\n",
            "Threads( StanfordCoreNLP ) [12:15.854 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the semantic self-supervision model performs better on referit -lrb- mask -rrb- compared to referit -lrb- bbox -rrb- because mask-based annotations are considered more precise and accurate for measuring localization performance than bounding boxes masks tightly encompass the specific region referred to by the phrase whereas bounding boxes can include extraneous areas this relates to the difference in performance between visual genome and flickr30k because both visual genome and referit -lrb- mask -rrb- contain phrases that refer to very specific regions or non-salient objects precise localization is crucial for achieving high accuracy on these datasets flickr30k on the other hand annotates all bounding boxes referring to a phrase leading to potentially less precise localization requirements and generally higher performance across methods\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the multi-hop encoder performs better on babi tasks 3 and 5 because these tasks specifically require inferencing over multiple kb tuples in other words the model needs to hop between different pieces of information in the knowledge base to make the correct inferences and recommendations task 3 involves sorting restaurants by rating and task 5 requires recommending a restaurant based on user preferences both tasks necessitate the model to consider various restaurant attributes and their relationships which the multi-hop encoder facilitates by capturing longer-range dependencies within the knowledge base\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the lstnet model has four main types of layers 1 convolutional layer this layer extracts local dependency patterns from the input data 2 recurrent and recurrent-skip layer these layers capture long-term dependencies in the data 3 fully connected and element-wise sum output layer this layer combines the outputs from the convolutional and recurrent layers to produce the final prediction 4 autoregressive layer this layer provides a linear bypass to the non-linear neural network part of the model the convolutional layer receives the input data and passes its output to the recurrent and recurrent-skip layers these layers then pass their output to the fully connected and element-wise sum output layer the autoregressive layer receives the input data directly and its output is also fed into the fully connected and element-wise sum output layer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the sdvi loss term 1 & 3 model only uses the pixel reconstruction loss and the inclusive kl divergence loss while the full sdvi model additionally incorporates the pixel prediction loss and the exclusive kl divergence loss according to the passage the exclusive kl divergence term encourages the inference distribution to be more accurate while the pixel prediction loss further improves video quality during inference therefore the absence of these terms in the sdvi loss term 1 & 3 model likely explains its inferior performance compared to the full sdvi model\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"both tf-idf and bm25 are features used to estimate the relevance of a document to a query however they differ in their underlying calculations tf-idf this feature represents the average product of term frequency -lrb- tf -rrb- and inverse document frequency -lrb- idf -rrb- for each query term within different document sections -lrb- url title content and whole document -rrb- tf measures how often a term appears in a specific document section while idf measures how important that term is across the entire document collection bm25 this feature utilizes the bm25 ranking function which is a probabilistic model that considers term frequency document length and average document length to estimate relevance while it also considers term frequency like tf-idf it incorporates additional factors to improve the weighting scheme\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"seq2sick differs from existing attack methods in two key aspects 1 search strategy while previous methods primarily rely on greedy search which becomes increasingly inefficient for longer sequences seq2sick employs group lasso regularization and projected gradient descent with gradient regularization this allows for simultaneous searching of all replacement positions leading to improved efficiency 2 targeted attack type existing methods focus on targeting specific classes or binary classifications while seq2sick introduces a novel keyword target type allowing attacks to be directed towards specific keywords within the generated sequence\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the five deformable cost volumes in devon 's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery this is achieved by using different neighborhood sizes -lrb- k -rrb- and dilation rates -lrb- r -rrb- for each cost volume as shown in table 1 smaller neighborhood sizes and dilation rates result in denser correspondences focusing on finer details and small displacements while larger values capture broader context and larger motions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"model xviii cig-sim & siam-gcn-sim $ ^ -lcb- g -rcb- $ achieves the best performance on the cnss dataset with an f1-score of 90.29 % this model utilizes the following key components 1 cig it directly uses keywords as concepts without community detection 2 sim & siam it employs both term-based similarity encoder -lrb- sim -rrb- and siamese encoder -lrb- siam -rrb- for generating matching vectors on vertices 3 gcn it performs convolution on local matching vectors through gcn layers 4 sim $ ^ -lcb- g -rcb- $ it incorporates additional global features based on the five term-based similarity metrics\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"it is difficult to definitively say which system performs better for low-quality captions based solely on the provided data however we can observe some trends 1 when the smt average rank is below 3 the cca average rank is also lower -lrb- 1.64 vs. 1.77 -rrb- 2 when the smt average rank is 3 or higher the cca average rank is significantly higher -lrb- 3.54 vs. 3.46 -rrb- this suggests that cca might perform relatively better for low-quality captions but more data and analysis are needed for a conclusive answer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"according to the table some common medications used to treat sickle cell anemia include beta-adrenergic agents analgesics -lrb- narcotics and non-narcotics -rrb- nsaids -lrb- cyclooxygenase inhibitor type -rrb- potassium replacement sodium/saline preparations general inhalation agents laxatives and cathartics iv solutions -lrb- dextrose-saline -rrb- antiemetic/antivertigo agents sedative-hypnotics -lrb- non-barbiturate -rrb- glucocorticoids -lrb- orally inhaled -rrb- folic acid preparations analgesic narcotic anesthetic adjunct agents\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"table 1 shows that coap has slightly higher reliability -lrb- 99.5 % -rrb- compared to tcplp -lrb- 99.3 % -rrb- while both protocols perform well this difference could be attributed to several factors including retransmission mechanisms coap employs a built-in retransmission mechanism for lost packets while tcplp relies on the underlying network layer for retransmissions this could give coap an edge in recovering lost packets and achieving higher reliability congestion control coap includes mechanisms to adapt to network congestion potentially reducing packet loss and improving reliability packet size coap typically uses smaller packets compared to tcplp smaller packets are less prone to loss in wireless networks potentially contributing to coap 's slightly higher reliability\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the actions that are most challenging for the network to recognize are those that include moving directions such as person move toward -lrb- home -rrb- person move away -lrb- home -rrb- and vehicle move toward -lrb- person -rrb- the proposed methods distance-based place discretization -lrb- dd -rrb- and topological feature aggregation -lrb- topo-agg -rrb- significantly improve the average precision on almost all action categories especially those that are more challenging and are associated with moving directions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the four steps involved in the synonym discovery process are 1 ** entity representation learning ** learn entity representations from the corpus using wembed 2 ** nn search ** perform a nearest neighbor search to find candidate entities for the query entity 3 ** synonym score calculation ** calculate the synonym score between the query entity and each candidate entity using synonym net 4 ** synonym entity discovery ** select the candidate entities with the highest synonym scores as the discovered synonym entities\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the table and passage show that the translation performance of the br-csgan model generally improves as the number of monte carlo samples -lrb- n -rrb- increases however this improvement plateaus after n reaches a certain point -lrb- around 20 in this case -rrb- there is a trade-off when choosing the value of n because increasing n also increases the computational complexity and training time while a higher n leads to more accurate reward estimations and better performance it also requires more computational resources and longer training times therefore choosing the optimal n involves balancing the desired performance with the available computational resources and time constraints\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"when the sample size is 2000 the two-phase framework -lrb- msg -rrb- achieves lower discrimination in prediction compared to di both with and without classifier tweaking with classifier tweaking msg achieves a discrimination level of 0.016 ± 5.3e-4 while di shows a significantly higher level of 0.095 ± 1.6e-3 without classifier tweaking msg still demonstrates lower discrimination with 0.067 ± 4.3e-3 compared to di 's 0.095 ± 1.6e-3 this indicates that the two-phase framework is more effective in removing discrimination from predictions than di regardless of whether classifier tweaking is applied\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"this paper shows that reattention helps alleviate both redundancy and deficiency in attention distributions redundancy reattention increases the kl divergence between adjacent attention blocks indicating that the attention distributions across blocks become more distinct and less redundant deficiency reattention reduces the kl divergence between the normalized attention distribution -lrb- $ e ^ t $ -rrb- and the ideal uniform distribution -lrb- $ -lcb- e ^ t -rcb- ^ * $ -rrb- suggesting that the attention becomes more balanced and closer to the desired distribution however the improvement in redundancy is more pronounced between the first two blocks -lrb- $ e ^ 1 $ to $ e ^ 2 $ -rrb- than the last two blocks -lrb- $ b ^ 2 $ to $ b ^ 3 $ -rrb- this suggests that the first reattention is more effective in capturing word pair similarities using the original word representations in contrast the later reattention might be negatively impacted by the highly non-linear word representations generated in the previous layers\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"while the model trained on both mot and detection sets shows improved performance in detection and tracking metrics -lrb- ap mota motp -rrb- it also exhibits a higher number of identity switches -lrb- ids -rrb- this can be attributed to the increased diversity of instances introduced by the detection set although the mot set provides a larger number of bounding boxes for training the detection set adds varied examples that may lead to more frequent identity switches during tracking even as it improves the model 's overall performance\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the training process uses several techniques to handle large vocabulary sizes these include 1 ** token-based batching ** instead of grouping sentences of similar lengths together the training process batches together a fixed number of tokens -lrb- 5120 tokens per batch -rrb- this approach ensures that the model sees a consistent amount of vocabulary regardless of sentence length variation 2 ** shared embedding ** this technique maps both source and target words to the same embedding space effectively reducing the memory footprint needed to store word representations 3 ** positional encoding ** this method injects information about the position of words in a sentence into the model helping it better understand long-range dependencies within the text\"\n",
            "Caption may be too long\n",
            "Parsing test captions\n",
            "Threads( StanfordCoreNLP ) [04:27.881 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"dataset of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images of images\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"choicenet is a method that is able to outperform other methods under different noise settings the method is able to outperform other methods under different noise settings the method is able to outperform other methods under different noise settings the method is able to outperform other methods under different noise settings the method is able to outperform other methods under different noise settings the method is able to outperform other methods under different noise settings the method is able to outperform other methods under different noise settings the method is able to outperform other methods under different noise settings the method is able to outperform other methods under different noise\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the procedure is based on the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the lstm network is a network of nodes that are connected by a set of hidden layers the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the outcome curve is a plot of the mean change in score for a group of students over time the selection rate is the number of students who are selected for each test the selection rate is the number of students who are selected for each test the selection rate is the number of students who are selected for each test the selection rate is the number of students who are selected for each test the selection rate is the number of students who are selected for each test the selection rate is the number of students who are selected for each test the selection rate is the number of students who are selected for each test the selection rate is the number of students who are selected for each test the selection rate is\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the translation performance of the model is strongly dependent on the number of monte carlo samples the translation performance of the model is strongly dependent on the number of monte carlo samples the translation performance of the model is strongly dependent on the number of monte carlo samples the translation performance of the model is strongly dependent on the number of monte carlo samples the translation performance of the model is strongly dependent on the number of monte carlo samples the translation performance of the model is strongly dependent on the number of monte carlo samples the translation performance of the model is strongly dependent on the number of monte carlo samples the translation performance of\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"choicenet is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the\"\n",
            "Caption may be too long\n",
            "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
            "SPICE evaluation took: 17.05 min\n",
            "SPICE: 0.227\n",
            "CIDEr: 0.890\n",
            "SPICE: 0.227\n",
            "BERTScore F1: 0.503\n",
            "Failed parsing: 0\n",
            "Samples evaluated: 666\n",
            "No-answer samples: 89\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python /content/MMML-Group-Project/metrics/cider_spice_eval.py --csv /content/MMML-Group-Project/data/blip2_results.csv --model_name resnet_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bkrOpna7j0lw",
        "outputId": "a2175795-7725-4771-edc4-8a7edbb67e63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-25 23:42:15.618032: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742946135.655122   10323 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742946135.666811   10323 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-25 23:42:15.709534: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "\n",
            "📄 Evaluating CSV: /content/MMML-Group-Project/data/blip2_results_256.csv (model: resnet_mlp)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 18943 tokens at 52584.31 tokens per second.\n",
            "PTBTokenizer tokenized 8369 tokens at 32492.94 tokens per second.\n",
            "setting up scorers...\n",
            "computing Bleu score...\n",
            "{'testlen': 7455, 'reflen': 16605, 'guess': [7455, 6870, 6377, 5914], 'correct': [3712, 2129, 1461, 980]}\n",
            "ratio: 0.4489611562782024\n",
            "Bleu_1: 0.146\n",
            "Bleu_2: 0.115\n",
            "Bleu_3: 0.096\n",
            "Bleu_4: 0.081\n",
            "computing METEOR score...\n",
            "METEOR: 0.118\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.243\n",
            "computing CIDEr score...\n",
            "CIDEr: 0.863\n",
            "computing SPICE score...\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
            "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Parsing reference captions\n",
            "Initiating Stanford parsing pipeline\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
            "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
            "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
            "done [1.5 sec].\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.7 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.0 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.1 sec].\n",
            "Threads( StanfordCoreNLP ) [04:43.48 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"while the model trained on both mot and detection sets shows improved performance in detection and tracking metrics -lrb- ap mota motp -rrb- it also exhibits a higher number of identity switches -lrb- ids -rrb- this can be attributed to the increased diversity of instances introduced by the detection set although the mot set provides a larger number of bounding boxes for training the detection set adds varied examples that may lead to more frequent identity switches during tracking even as it improves the model 's overall performance\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the table and passage show that the translation performance of the br-csgan model generally improves as the number of monte carlo samples -lrb- n -rrb- increases however this improvement plateaus after n reaches a certain point -lrb- around 20 in this case -rrb- there is a trade-off when choosing the value of n because increasing n also increases the computational complexity and training time while a higher n leads to more accurate reward estimations and better performance it also requires more computational resources and longer training times therefore choosing the optimal n involves balancing the desired performance with the available computational resources and time constraints\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the lstnet model has four main types of layers 1 convolutional layer this layer extracts local dependency patterns from the input data 2 recurrent and recurrent-skip layer these layers capture long-term dependencies in the data 3 fully connected and element-wise sum output layer this layer combines the outputs from the convolutional and recurrent layers to produce the final prediction 4 autoregressive layer this layer provides a linear bypass to the non-linear neural network part of the model the convolutional layer receives the input data and passes its output to the recurrent and recurrent-skip layers these layers then pass their output to the fully connected and element-wise sum output layer the autoregressive layer receives the input data directly and its output is also fed into the fully connected and element-wise sum output layer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"this paper shows that reattention helps alleviate both redundancy and deficiency in attention distributions redundancy reattention increases the kl divergence between adjacent attention blocks indicating that the attention distributions across blocks become more distinct and less redundant deficiency reattention reduces the kl divergence between the normalized attention distribution -lrb- $ e ^ t $ -rrb- and the ideal uniform distribution -lrb- $ -lcb- e ^ t -rcb- ^ * $ -rrb- suggesting that the attention becomes more balanced and closer to the desired distribution however the improvement in redundancy is more pronounced between the first two blocks -lrb- $ e ^ 1 $ to $ e ^ 2 $ -rrb- than the last two blocks -lrb- $ b ^ 2 $ to $ b ^ 3 $ -rrb- this suggests that the first reattention is more effective in capturing word pair similarities using the original word representations in contrast the later reattention might be negatively impacted by the highly non-linear word representations generated in the previous layers\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the training process uses several techniques to handle large vocabulary sizes these include 1 ** token-based batching ** instead of grouping sentences of similar lengths together the training process batches together a fixed number of tokens -lrb- 5120 tokens per batch -rrb- this approach ensures that the model sees a consistent amount of vocabulary regardless of sentence length variation 2 ** shared embedding ** this technique maps both source and target words to the same embedding space effectively reducing the memory footprint needed to store word representations 3 ** positional encoding ** this method injects information about the position of words in a sentence into the model helping it better understand long-range dependencies within the text\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"both tf-idf and bm25 are features used to estimate the relevance of a document to a query however they differ in their underlying calculations tf-idf this feature represents the average product of term frequency -lrb- tf -rrb- and inverse document frequency -lrb- idf -rrb- for each query term within different document sections -lrb- url title content and whole document -rrb- tf measures how often a term appears in a specific document section while idf measures how important that term is across the entire document collection bm25 this feature utilizes the bm25 ranking function which is a probabilistic model that considers term frequency document length and average document length to estimate relevance while it also considers term frequency like tf-idf it incorporates additional factors to improve the weighting scheme\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"model xviii cig-sim & siam-gcn-sim $ ^ -lcb- g -rcb- $ achieves the best performance on the cnss dataset with an f1-score of 90.29 % this model utilizes the following key components 1 cig it directly uses keywords as concepts without community detection 2 sim & siam it employs both term-based similarity encoder -lrb- sim -rrb- and siamese encoder -lrb- siam -rrb- for generating matching vectors on vertices 3 gcn it performs convolution on local matching vectors through gcn layers 4 sim $ ^ -lcb- g -rcb- $ it incorporates additional global features based on the five term-based similarity metrics\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the actions that are most challenging for the network to recognize are those that include moving directions such as person move toward -lrb- home -rrb- person move away -lrb- home -rrb- and vehicle move toward -lrb- person -rrb- the proposed methods distance-based place discretization -lrb- dd -rrb- and topological feature aggregation -lrb- topo-agg -rrb- significantly improve the average precision on almost all action categories especially those that are more challenging and are associated with moving directions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"when the sample size is 2000 the two-phase framework -lrb- msg -rrb- achieves lower discrimination in prediction compared to di both with and without classifier tweaking with classifier tweaking msg achieves a discrimination level of 0.016 ± 5.3e-4 while di shows a significantly higher level of 0.095 ± 1.6e-3 without classifier tweaking msg still demonstrates lower discrimination with 0.067 ± 4.3e-3 compared to di 's 0.095 ± 1.6e-3 this indicates that the two-phase framework is more effective in removing discrimination from predictions than di regardless of whether classifier tweaking is applied\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the multi-hop encoder performs better on babi tasks 3 and 5 because these tasks specifically require inferencing over multiple kb tuples in other words the model needs to hop between different pieces of information in the knowledge base to make the correct inferences and recommendations task 3 involves sorting restaurants by rating and task 5 requires recommending a restaurant based on user preferences both tasks necessitate the model to consider various restaurant attributes and their relationships which the multi-hop encoder facilitates by capturing longer-range dependencies within the knowledge base\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the five deformable cost volumes in devon 's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery this is achieved by using different neighborhood sizes -lrb- k -rrb- and dilation rates -lrb- r -rrb- for each cost volume as shown in table 1 smaller neighborhood sizes and dilation rates result in denser correspondences focusing on finer details and small displacements while larger values capture broader context and larger motions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"table 1 shows that coap has slightly higher reliability -lrb- 99.5 % -rrb- compared to tcplp -lrb- 99.3 % -rrb- while both protocols perform well this difference could be attributed to several factors including retransmission mechanisms coap employs a built-in retransmission mechanism for lost packets while tcplp relies on the underlying network layer for retransmissions this could give coap an edge in recovering lost packets and achieving higher reliability congestion control coap includes mechanisms to adapt to network congestion potentially reducing packet loss and improving reliability packet size coap typically uses smaller packets compared to tcplp smaller packets are less prone to loss in wireless networks potentially contributing to coap 's slightly higher reliability\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"it is difficult to definitively say which system performs better for low-quality captions based solely on the provided data however we can observe some trends 1 when the smt average rank is below 3 the cca average rank is also lower -lrb- 1.64 vs. 1.77 -rrb- 2 when the smt average rank is 3 or higher the cca average rank is significantly higher -lrb- 3.54 vs. 3.46 -rrb- this suggests that cca might perform relatively better for low-quality captions but more data and analysis are needed for a conclusive answer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the semantic self-supervision model performs better on referit -lrb- mask -rrb- compared to referit -lrb- bbox -rrb- because mask-based annotations are considered more precise and accurate for measuring localization performance than bounding boxes masks tightly encompass the specific region referred to by the phrase whereas bounding boxes can include extraneous areas this relates to the difference in performance between visual genome and flickr30k because both visual genome and referit -lrb- mask -rrb- contain phrases that refer to very specific regions or non-salient objects precise localization is crucial for achieving high accuracy on these datasets flickr30k on the other hand annotates all bounding boxes referring to a phrase leading to potentially less precise localization requirements and generally higher performance across methods\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the sdvi loss term 1 & 3 model only uses the pixel reconstruction loss and the inclusive kl divergence loss while the full sdvi model additionally incorporates the pixel prediction loss and the exclusive kl divergence loss according to the passage the exclusive kl divergence term encourages the inference distribution to be more accurate while the pixel prediction loss further improves video quality during inference therefore the absence of these terms in the sdvi loss term 1 & 3 model likely explains its inferior performance compared to the full sdvi model\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"according to the table some common medications used to treat sickle cell anemia include beta-adrenergic agents analgesics -lrb- narcotics and non-narcotics -rrb- nsaids -lrb- cyclooxygenase inhibitor type -rrb- potassium replacement sodium/saline preparations general inhalation agents laxatives and cathartics iv solutions -lrb- dextrose-saline -rrb- antiemetic/antivertigo agents sedative-hypnotics -lrb- non-barbiturate -rrb- glucocorticoids -lrb- orally inhaled -rrb- folic acid preparations analgesic narcotic anesthetic adjunct agents\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the four steps involved in the synonym discovery process are 1 ** entity representation learning ** learn entity representations from the corpus using wembed 2 ** nn search ** perform a nearest neighbor search to find candidate entities for the query entity 3 ** synonym score calculation ** calculate the synonym score between the query entity and each candidate entity using synonym net 4 ** synonym entity discovery ** select the candidate entities with the highest synonym scores as the discovered synonym entities\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"seq2sick differs from existing attack methods in two key aspects 1 search strategy while previous methods primarily rely on greedy search which becomes increasingly inefficient for longer sequences seq2sick employs group lasso regularization and projected gradient descent with gradient regularization this allows for simultaneous searching of all replacement positions leading to improved efficiency 2 targeted attack type existing methods focus on targeting specific classes or binary classifications while seq2sick introduces a novel keyword target type allowing attacks to be directed towards specific keywords within the generated sequence\"\n",
            "Caption may be too long\n",
            "Parsing test captions\n",
            "Threads( StanfordCoreNLP ) [01:58.622 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"deep residual networks are built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"choicenet is a method that is designed to measure the performance of a network of nodes in a network of nodes it is a method that is designed to measure the performance of a network of nodes in a network of nodes it is a method that is designed to measure the performance of a network of nodes in a network of nodes it is a method that is designed to measure the performance of a network of nodes in a network of nodes it is a method that is designed to measure the performance of a network of nodes in a network of nodes it is a method that is designed to measure the performance of a network of nodes in a network of nodes it is a\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the shortcuts in the visual7w dataset can be remedied by using the following steps 1 -rrb- select the image in the dataset and click on the uncover button 2 -rrb- select the image in the dataset and click on the uncover button 3 -rrb- select the image in the dataset and click on the uncover button 4 -rrb- select the image in the dataset and click on the uncover button 5 -rrb- select the image in the dataset and click on the uncover button 6 -rrb- select the image in the dataset and click on the uncover button 7 -rrb- select the image in the dataset and click on the uncover button 8 -rrb- select the image\"\n",
            "Caption may be too long\n",
            "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
            "SPICE evaluation took: 6.933 min\n",
            "SPICE: 0.226\n",
            "CIDEr: 0.863\n",
            "SPICE: 0.226\n",
            "BERTScore F1: 0.506\n",
            "Failed parsing: 0\n",
            "Samples evaluated: 666\n",
            "No-answer samples: 81\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python /content/MMML-Group-Project/metrics/cider_spice_eval.py --csv /content/MMML-Group-Project/data/blip2_results_256.csv --model_name resnet_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ezZX1n5Ck4Q-",
        "outputId": "57dba790-7c1c-488d-ec27-f93768d6ba9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-25 23:52:52.406921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742946772.467552   12952 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742946772.485041   12952 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-25 23:52:52.550465: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "\n",
            "📄 Evaluating CSV: /content/MMML-Group-Project/data/blip2_results_512.csv (model: resnet_mlp)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 18943 tokens at 49346.11 tokens per second.\n",
            "PTBTokenizer tokenized 8621 tokens at 33037.45 tokens per second.\n",
            "setting up scorers...\n",
            "computing Bleu score...\n",
            "{'testlen': 7727, 'reflen': 16605, 'guess': [7727, 7143, 6656, 6199], 'correct': [3755, 2129, 1452, 973]}\n",
            "ratio: 0.4653417645287284\n",
            "Bleu_1: 0.154\n",
            "Bleu_2: 0.121\n",
            "Bleu_3: 0.100\n",
            "Bleu_4: 0.084\n",
            "computing METEOR score...\n",
            "METEOR: 0.119\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.243\n",
            "computing CIDEr score...\n",
            "CIDEr: 0.887\n",
            "computing SPICE score...\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
            "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Parsing reference captions\n",
            "Initiating Stanford parsing pipeline\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
            "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
            "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
            "done [2.1 sec].\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.7 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.2 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
            "Threads( StanfordCoreNLP ) [04:51.130 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"while the model trained on both mot and detection sets shows improved performance in detection and tracking metrics -lrb- ap mota motp -rrb- it also exhibits a higher number of identity switches -lrb- ids -rrb- this can be attributed to the increased diversity of instances introduced by the detection set although the mot set provides a larger number of bounding boxes for training the detection set adds varied examples that may lead to more frequent identity switches during tracking even as it improves the model 's overall performance\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the table and passage show that the translation performance of the br-csgan model generally improves as the number of monte carlo samples -lrb- n -rrb- increases however this improvement plateaus after n reaches a certain point -lrb- around 20 in this case -rrb- there is a trade-off when choosing the value of n because increasing n also increases the computational complexity and training time while a higher n leads to more accurate reward estimations and better performance it also requires more computational resources and longer training times therefore choosing the optimal n involves balancing the desired performance with the available computational resources and time constraints\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the lstnet model has four main types of layers 1 convolutional layer this layer extracts local dependency patterns from the input data 2 recurrent and recurrent-skip layer these layers capture long-term dependencies in the data 3 fully connected and element-wise sum output layer this layer combines the outputs from the convolutional and recurrent layers to produce the final prediction 4 autoregressive layer this layer provides a linear bypass to the non-linear neural network part of the model the convolutional layer receives the input data and passes its output to the recurrent and recurrent-skip layers these layers then pass their output to the fully connected and element-wise sum output layer the autoregressive layer receives the input data directly and its output is also fed into the fully connected and element-wise sum output layer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"this paper shows that reattention helps alleviate both redundancy and deficiency in attention distributions redundancy reattention increases the kl divergence between adjacent attention blocks indicating that the attention distributions across blocks become more distinct and less redundant deficiency reattention reduces the kl divergence between the normalized attention distribution -lrb- $ e ^ t $ -rrb- and the ideal uniform distribution -lrb- $ -lcb- e ^ t -rcb- ^ * $ -rrb- suggesting that the attention becomes more balanced and closer to the desired distribution however the improvement in redundancy is more pronounced between the first two blocks -lrb- $ e ^ 1 $ to $ e ^ 2 $ -rrb- than the last two blocks -lrb- $ b ^ 2 $ to $ b ^ 3 $ -rrb- this suggests that the first reattention is more effective in capturing word pair similarities using the original word representations in contrast the later reattention might be negatively impacted by the highly non-linear word representations generated in the previous layers\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the training process uses several techniques to handle large vocabulary sizes these include 1 ** token-based batching ** instead of grouping sentences of similar lengths together the training process batches together a fixed number of tokens -lrb- 5120 tokens per batch -rrb- this approach ensures that the model sees a consistent amount of vocabulary regardless of sentence length variation 2 ** shared embedding ** this technique maps both source and target words to the same embedding space effectively reducing the memory footprint needed to store word representations 3 ** positional encoding ** this method injects information about the position of words in a sentence into the model helping it better understand long-range dependencies within the text\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"both tf-idf and bm25 are features used to estimate the relevance of a document to a query however they differ in their underlying calculations tf-idf this feature represents the average product of term frequency -lrb- tf -rrb- and inverse document frequency -lrb- idf -rrb- for each query term within different document sections -lrb- url title content and whole document -rrb- tf measures how often a term appears in a specific document section while idf measures how important that term is across the entire document collection bm25 this feature utilizes the bm25 ranking function which is a probabilistic model that considers term frequency document length and average document length to estimate relevance while it also considers term frequency like tf-idf it incorporates additional factors to improve the weighting scheme\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"model xviii cig-sim & siam-gcn-sim $ ^ -lcb- g -rcb- $ achieves the best performance on the cnss dataset with an f1-score of 90.29 % this model utilizes the following key components 1 cig it directly uses keywords as concepts without community detection 2 sim & siam it employs both term-based similarity encoder -lrb- sim -rrb- and siamese encoder -lrb- siam -rrb- for generating matching vectors on vertices 3 gcn it performs convolution on local matching vectors through gcn layers 4 sim $ ^ -lcb- g -rcb- $ it incorporates additional global features based on the five term-based similarity metrics\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the actions that are most challenging for the network to recognize are those that include moving directions such as person move toward -lrb- home -rrb- person move away -lrb- home -rrb- and vehicle move toward -lrb- person -rrb- the proposed methods distance-based place discretization -lrb- dd -rrb- and topological feature aggregation -lrb- topo-agg -rrb- significantly improve the average precision on almost all action categories especially those that are more challenging and are associated with moving directions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"when the sample size is 2000 the two-phase framework -lrb- msg -rrb- achieves lower discrimination in prediction compared to di both with and without classifier tweaking with classifier tweaking msg achieves a discrimination level of 0.016 ± 5.3e-4 while di shows a significantly higher level of 0.095 ± 1.6e-3 without classifier tweaking msg still demonstrates lower discrimination with 0.067 ± 4.3e-3 compared to di 's 0.095 ± 1.6e-3 this indicates that the two-phase framework is more effective in removing discrimination from predictions than di regardless of whether classifier tweaking is applied\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the multi-hop encoder performs better on babi tasks 3 and 5 because these tasks specifically require inferencing over multiple kb tuples in other words the model needs to hop between different pieces of information in the knowledge base to make the correct inferences and recommendations task 3 involves sorting restaurants by rating and task 5 requires recommending a restaurant based on user preferences both tasks necessitate the model to consider various restaurant attributes and their relationships which the multi-hop encoder facilitates by capturing longer-range dependencies within the knowledge base\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the five deformable cost volumes in devon 's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery this is achieved by using different neighborhood sizes -lrb- k -rrb- and dilation rates -lrb- r -rrb- for each cost volume as shown in table 1 smaller neighborhood sizes and dilation rates result in denser correspondences focusing on finer details and small displacements while larger values capture broader context and larger motions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"table 1 shows that coap has slightly higher reliability -lrb- 99.5 % -rrb- compared to tcplp -lrb- 99.3 % -rrb- while both protocols perform well this difference could be attributed to several factors including retransmission mechanisms coap employs a built-in retransmission mechanism for lost packets while tcplp relies on the underlying network layer for retransmissions this could give coap an edge in recovering lost packets and achieving higher reliability congestion control coap includes mechanisms to adapt to network congestion potentially reducing packet loss and improving reliability packet size coap typically uses smaller packets compared to tcplp smaller packets are less prone to loss in wireless networks potentially contributing to coap 's slightly higher reliability\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"it is difficult to definitively say which system performs better for low-quality captions based solely on the provided data however we can observe some trends 1 when the smt average rank is below 3 the cca average rank is also lower -lrb- 1.64 vs. 1.77 -rrb- 2 when the smt average rank is 3 or higher the cca average rank is significantly higher -lrb- 3.54 vs. 3.46 -rrb- this suggests that cca might perform relatively better for low-quality captions but more data and analysis are needed for a conclusive answer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the semantic self-supervision model performs better on referit -lrb- mask -rrb- compared to referit -lrb- bbox -rrb- because mask-based annotations are considered more precise and accurate for measuring localization performance than bounding boxes masks tightly encompass the specific region referred to by the phrase whereas bounding boxes can include extraneous areas this relates to the difference in performance between visual genome and flickr30k because both visual genome and referit -lrb- mask -rrb- contain phrases that refer to very specific regions or non-salient objects precise localization is crucial for achieving high accuracy on these datasets flickr30k on the other hand annotates all bounding boxes referring to a phrase leading to potentially less precise localization requirements and generally higher performance across methods\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the sdvi loss term 1 & 3 model only uses the pixel reconstruction loss and the inclusive kl divergence loss while the full sdvi model additionally incorporates the pixel prediction loss and the exclusive kl divergence loss according to the passage the exclusive kl divergence term encourages the inference distribution to be more accurate while the pixel prediction loss further improves video quality during inference therefore the absence of these terms in the sdvi loss term 1 & 3 model likely explains its inferior performance compared to the full sdvi model\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"according to the table some common medications used to treat sickle cell anemia include beta-adrenergic agents analgesics -lrb- narcotics and non-narcotics -rrb- nsaids -lrb- cyclooxygenase inhibitor type -rrb- potassium replacement sodium/saline preparations general inhalation agents laxatives and cathartics iv solutions -lrb- dextrose-saline -rrb- antiemetic/antivertigo agents sedative-hypnotics -lrb- non-barbiturate -rrb- glucocorticoids -lrb- orally inhaled -rrb- folic acid preparations analgesic narcotic anesthetic adjunct agents\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the four steps involved in the synonym discovery process are 1 ** entity representation learning ** learn entity representations from the corpus using wembed 2 ** nn search ** perform a nearest neighbor search to find candidate entities for the query entity 3 ** synonym score calculation ** calculate the synonym score between the query entity and each candidate entity using synonym net 4 ** synonym entity discovery ** select the candidate entities with the highest synonym scores as the discovered synonym entities\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"seq2sick differs from existing attack methods in two key aspects 1 search strategy while previous methods primarily rely on greedy search which becomes increasingly inefficient for longer sequences seq2sick employs group lasso regularization and projected gradient descent with gradient regularization this allows for simultaneous searching of all replacement positions leading to improved efficiency 2 targeted attack type existing methods focus on targeting specific classes or binary classifications while seq2sick introduces a novel keyword target type allowing attacks to be directed towards specific keywords within the generated sequence\"\n",
            "Caption may be too long\n",
            "Parsing test captions\n",
            "Threads( StanfordCoreNLP ) [02:49.41 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and the cityscapes dataset is a subset of the dataset and\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"choicenet is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the principle of random forest which is a method that is based on the\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the procedure is based on the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the principle of the\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the lstm network is a network of nodes that are connected by a set of hidden layers the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden layers are used to model the hidden layers of the network the hidden\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the steps are 1 -rrb- the induction of a latent semantic network -lrb- lsn -rrb- from the latent semantic features -lrb- lsfs -rrb- of the argument 2 -rrb- the induction of a latent semantic model -lrb- lsm -rrb- from the lsfs of the argument 3 -rrb- the induction of a latent semantic model -lrb- lsm -rrb- from the lsms of the argument 4 -rrb- the induction of a latent semantic model -lrb- lsm -rrb- from the lsms of the argument 5 -rrb- the induction of a latent semantic model -lrb- lsm -rrb- from the lsms of the argument 6 -rrb- the induction of a latent semantic model -lrb- lsm -rrb- from the lsms of the argument 7 -rrb- the induction of a\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"deep residual networks are built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking the output of a network built by stacking\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning rate was the task that required the highest learning\"\n",
            "Caption may be too long\n",
            "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
            "SPICE evaluation took: 7.917 min\n",
            "SPICE: 0.229\n",
            "CIDEr: 0.887\n",
            "SPICE: 0.229\n",
            "BERTScore F1: 0.508\n",
            "Failed parsing: 0\n",
            "Samples evaluated: 666\n",
            "No-answer samples: 82\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python /content/MMML-Group-Project/metrics/cider_spice_eval.py --csv /content/MMML-Group-Project/data/blip2_results_512.csv --model_name resnet_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K31J4Z4Lk6BV",
        "outputId": "454adf23-3993-4ad9-a45f-4723b938859e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-26 00:04:29.789468: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742947469.832118   15817 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742947469.843876   15817 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-26 00:04:29.886644: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "\n",
            "📄 Evaluating CSV: /content/MMML-Group-Project/data/blip_results.csv (model: resnet_mlp)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 18943 tokens at 51787.47 tokens per second.\n",
            "PTBTokenizer tokenized 1634 tokens at 11089.65 tokens per second.\n",
            "setting up scorers...\n",
            "computing Bleu score...\n",
            "{'testlen': 952, 'reflen': 16605, 'guess': [952, 289, 113, 35], 'correct': [72, 0, 0, 0]}\n",
            "ratio: 0.05733212887684087\n",
            "Bleu_1: 0.000\n",
            "Bleu_2: 0.000\n",
            "Bleu_3: 0.000\n",
            "Bleu_4: 0.000\n",
            "computing METEOR score...\n",
            "METEOR: 0.003\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.009\n",
            "computing CIDEr score...\n",
            "CIDEr: 0.006\n",
            "computing SPICE score...\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
            "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Parsing reference captions\n",
            "Initiating Stanford parsing pipeline\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
            "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
            "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
            "done [1.9 sec].\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [3.3 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.2 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.1 sec].\n",
            "Threads( StanfordCoreNLP ) [05:04.66 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"while the model trained on both mot and detection sets shows improved performance in detection and tracking metrics -lrb- ap mota motp -rrb- it also exhibits a higher number of identity switches -lrb- ids -rrb- this can be attributed to the increased diversity of instances introduced by the detection set although the mot set provides a larger number of bounding boxes for training the detection set adds varied examples that may lead to more frequent identity switches during tracking even as it improves the model 's overall performance\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the table and passage show that the translation performance of the br-csgan model generally improves as the number of monte carlo samples -lrb- n -rrb- increases however this improvement plateaus after n reaches a certain point -lrb- around 20 in this case -rrb- there is a trade-off when choosing the value of n because increasing n also increases the computational complexity and training time while a higher n leads to more accurate reward estimations and better performance it also requires more computational resources and longer training times therefore choosing the optimal n involves balancing the desired performance with the available computational resources and time constraints\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the lstnet model has four main types of layers 1 convolutional layer this layer extracts local dependency patterns from the input data 2 recurrent and recurrent-skip layer these layers capture long-term dependencies in the data 3 fully connected and element-wise sum output layer this layer combines the outputs from the convolutional and recurrent layers to produce the final prediction 4 autoregressive layer this layer provides a linear bypass to the non-linear neural network part of the model the convolutional layer receives the input data and passes its output to the recurrent and recurrent-skip layers these layers then pass their output to the fully connected and element-wise sum output layer the autoregressive layer receives the input data directly and its output is also fed into the fully connected and element-wise sum output layer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"this paper shows that reattention helps alleviate both redundancy and deficiency in attention distributions redundancy reattention increases the kl divergence between adjacent attention blocks indicating that the attention distributions across blocks become more distinct and less redundant deficiency reattention reduces the kl divergence between the normalized attention distribution -lrb- $ e ^ t $ -rrb- and the ideal uniform distribution -lrb- $ -lcb- e ^ t -rcb- ^ * $ -rrb- suggesting that the attention becomes more balanced and closer to the desired distribution however the improvement in redundancy is more pronounced between the first two blocks -lrb- $ e ^ 1 $ to $ e ^ 2 $ -rrb- than the last two blocks -lrb- $ b ^ 2 $ to $ b ^ 3 $ -rrb- this suggests that the first reattention is more effective in capturing word pair similarities using the original word representations in contrast the later reattention might be negatively impacted by the highly non-linear word representations generated in the previous layers\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the training process uses several techniques to handle large vocabulary sizes these include 1 ** token-based batching ** instead of grouping sentences of similar lengths together the training process batches together a fixed number of tokens -lrb- 5120 tokens per batch -rrb- this approach ensures that the model sees a consistent amount of vocabulary regardless of sentence length variation 2 ** shared embedding ** this technique maps both source and target words to the same embedding space effectively reducing the memory footprint needed to store word representations 3 ** positional encoding ** this method injects information about the position of words in a sentence into the model helping it better understand long-range dependencies within the text\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"both tf-idf and bm25 are features used to estimate the relevance of a document to a query however they differ in their underlying calculations tf-idf this feature represents the average product of term frequency -lrb- tf -rrb- and inverse document frequency -lrb- idf -rrb- for each query term within different document sections -lrb- url title content and whole document -rrb- tf measures how often a term appears in a specific document section while idf measures how important that term is across the entire document collection bm25 this feature utilizes the bm25 ranking function which is a probabilistic model that considers term frequency document length and average document length to estimate relevance while it also considers term frequency like tf-idf it incorporates additional factors to improve the weighting scheme\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"model xviii cig-sim & siam-gcn-sim $ ^ -lcb- g -rcb- $ achieves the best performance on the cnss dataset with an f1-score of 90.29 % this model utilizes the following key components 1 cig it directly uses keywords as concepts without community detection 2 sim & siam it employs both term-based similarity encoder -lrb- sim -rrb- and siamese encoder -lrb- siam -rrb- for generating matching vectors on vertices 3 gcn it performs convolution on local matching vectors through gcn layers 4 sim $ ^ -lcb- g -rcb- $ it incorporates additional global features based on the five term-based similarity metrics\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the actions that are most challenging for the network to recognize are those that include moving directions such as person move toward -lrb- home -rrb- person move away -lrb- home -rrb- and vehicle move toward -lrb- person -rrb- the proposed methods distance-based place discretization -lrb- dd -rrb- and topological feature aggregation -lrb- topo-agg -rrb- significantly improve the average precision on almost all action categories especially those that are more challenging and are associated with moving directions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"when the sample size is 2000 the two-phase framework -lrb- msg -rrb- achieves lower discrimination in prediction compared to di both with and without classifier tweaking with classifier tweaking msg achieves a discrimination level of 0.016 ± 5.3e-4 while di shows a significantly higher level of 0.095 ± 1.6e-3 without classifier tweaking msg still demonstrates lower discrimination with 0.067 ± 4.3e-3 compared to di 's 0.095 ± 1.6e-3 this indicates that the two-phase framework is more effective in removing discrimination from predictions than di regardless of whether classifier tweaking is applied\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the multi-hop encoder performs better on babi tasks 3 and 5 because these tasks specifically require inferencing over multiple kb tuples in other words the model needs to hop between different pieces of information in the knowledge base to make the correct inferences and recommendations task 3 involves sorting restaurants by rating and task 5 requires recommending a restaurant based on user preferences both tasks necessitate the model to consider various restaurant attributes and their relationships which the multi-hop encoder facilitates by capturing longer-range dependencies within the knowledge base\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the five deformable cost volumes in devon 's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery this is achieved by using different neighborhood sizes -lrb- k -rrb- and dilation rates -lrb- r -rrb- for each cost volume as shown in table 1 smaller neighborhood sizes and dilation rates result in denser correspondences focusing on finer details and small displacements while larger values capture broader context and larger motions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"table 1 shows that coap has slightly higher reliability -lrb- 99.5 % -rrb- compared to tcplp -lrb- 99.3 % -rrb- while both protocols perform well this difference could be attributed to several factors including retransmission mechanisms coap employs a built-in retransmission mechanism for lost packets while tcplp relies on the underlying network layer for retransmissions this could give coap an edge in recovering lost packets and achieving higher reliability congestion control coap includes mechanisms to adapt to network congestion potentially reducing packet loss and improving reliability packet size coap typically uses smaller packets compared to tcplp smaller packets are less prone to loss in wireless networks potentially contributing to coap 's slightly higher reliability\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"it is difficult to definitively say which system performs better for low-quality captions based solely on the provided data however we can observe some trends 1 when the smt average rank is below 3 the cca average rank is also lower -lrb- 1.64 vs. 1.77 -rrb- 2 when the smt average rank is 3 or higher the cca average rank is significantly higher -lrb- 3.54 vs. 3.46 -rrb- this suggests that cca might perform relatively better for low-quality captions but more data and analysis are needed for a conclusive answer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the semantic self-supervision model performs better on referit -lrb- mask -rrb- compared to referit -lrb- bbox -rrb- because mask-based annotations are considered more precise and accurate for measuring localization performance than bounding boxes masks tightly encompass the specific region referred to by the phrase whereas bounding boxes can include extraneous areas this relates to the difference in performance between visual genome and flickr30k because both visual genome and referit -lrb- mask -rrb- contain phrases that refer to very specific regions or non-salient objects precise localization is crucial for achieving high accuracy on these datasets flickr30k on the other hand annotates all bounding boxes referring to a phrase leading to potentially less precise localization requirements and generally higher performance across methods\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the sdvi loss term 1 & 3 model only uses the pixel reconstruction loss and the inclusive kl divergence loss while the full sdvi model additionally incorporates the pixel prediction loss and the exclusive kl divergence loss according to the passage the exclusive kl divergence term encourages the inference distribution to be more accurate while the pixel prediction loss further improves video quality during inference therefore the absence of these terms in the sdvi loss term 1 & 3 model likely explains its inferior performance compared to the full sdvi model\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"according to the table some common medications used to treat sickle cell anemia include beta-adrenergic agents analgesics -lrb- narcotics and non-narcotics -rrb- nsaids -lrb- cyclooxygenase inhibitor type -rrb- potassium replacement sodium/saline preparations general inhalation agents laxatives and cathartics iv solutions -lrb- dextrose-saline -rrb- antiemetic/antivertigo agents sedative-hypnotics -lrb- non-barbiturate -rrb- glucocorticoids -lrb- orally inhaled -rrb- folic acid preparations analgesic narcotic anesthetic adjunct agents\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the four steps involved in the synonym discovery process are 1 ** entity representation learning ** learn entity representations from the corpus using wembed 2 ** nn search ** perform a nearest neighbor search to find candidate entities for the query entity 3 ** synonym score calculation ** calculate the synonym score between the query entity and each candidate entity using synonym net 4 ** synonym entity discovery ** select the candidate entities with the highest synonym scores as the discovered synonym entities\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"seq2sick differs from existing attack methods in two key aspects 1 search strategy while previous methods primarily rely on greedy search which becomes increasingly inefficient for longer sequences seq2sick employs group lasso regularization and projected gradient descent with gradient regularization this allows for simultaneous searching of all replacement positions leading to improved efficiency 2 targeted attack type existing methods focus on targeting specific classes or binary classifications while seq2sick introduces a novel keyword target type allowing attacks to be directed towards specific keywords within the generated sequence\"\n",
            "Caption may be too long\n",
            "Parsing test captions\n",
            "Threads( StanfordCoreNLP ) [2.633 seconds]\n",
            "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
            "SPICE evaluation took: 5.361 min\n",
            "SPICE: 0.002\n",
            "CIDEr: 0.006\n",
            "SPICE: 0.002\n",
            "BERTScore F1: 0.306\n",
            "Failed parsing: 0\n",
            "Samples evaluated: 666\n",
            "No-answer samples: 3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python /content/MMML-Group-Project/metrics/cider_spice_eval.py --csv /content/MMML-Group-Project/data/blip_results.csv --model_name resnet_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Usohexqgk9A1",
        "outputId": "d089fd26-9988-4a3b-9c48-b1f3ba2dc4b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-26 00:13:23.017937: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742948003.046667   18050 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742948003.054757   18050 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-26 00:13:23.082840: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "\n",
            "📄 Evaluating CSV: /content/MMML-Group-Project/data/blip_results_256.csv (model: resnet_mlp)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 18943 tokens at 47252.59 tokens per second.\n",
            "PTBTokenizer tokenized 1700 tokens at 11835.35 tokens per second.\n",
            "setting up scorers...\n",
            "computing Bleu score...\n",
            "{'testlen': 1016, 'reflen': 16605, 'guess': [1016, 353, 160, 58], 'correct': [88, 0, 0, 0]}\n",
            "ratio: 0.06118638964167051\n",
            "Bleu_1: 0.000\n",
            "Bleu_2: 0.000\n",
            "Bleu_3: 0.000\n",
            "Bleu_4: 0.000\n",
            "computing METEOR score...\n",
            "METEOR: 0.003\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.010\n",
            "computing CIDEr score...\n",
            "CIDEr: 0.007\n",
            "computing SPICE score...\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
            "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Parsing reference captions\n",
            "Initiating Stanford parsing pipeline\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
            "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
            "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
            "done [1.2 sec].\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.5 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.4 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
            "Threads( StanfordCoreNLP ) [04:34.99 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"while the model trained on both mot and detection sets shows improved performance in detection and tracking metrics -lrb- ap mota motp -rrb- it also exhibits a higher number of identity switches -lrb- ids -rrb- this can be attributed to the increased diversity of instances introduced by the detection set although the mot set provides a larger number of bounding boxes for training the detection set adds varied examples that may lead to more frequent identity switches during tracking even as it improves the model 's overall performance\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the table and passage show that the translation performance of the br-csgan model generally improves as the number of monte carlo samples -lrb- n -rrb- increases however this improvement plateaus after n reaches a certain point -lrb- around 20 in this case -rrb- there is a trade-off when choosing the value of n because increasing n also increases the computational complexity and training time while a higher n leads to more accurate reward estimations and better performance it also requires more computational resources and longer training times therefore choosing the optimal n involves balancing the desired performance with the available computational resources and time constraints\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the lstnet model has four main types of layers 1 convolutional layer this layer extracts local dependency patterns from the input data 2 recurrent and recurrent-skip layer these layers capture long-term dependencies in the data 3 fully connected and element-wise sum output layer this layer combines the outputs from the convolutional and recurrent layers to produce the final prediction 4 autoregressive layer this layer provides a linear bypass to the non-linear neural network part of the model the convolutional layer receives the input data and passes its output to the recurrent and recurrent-skip layers these layers then pass their output to the fully connected and element-wise sum output layer the autoregressive layer receives the input data directly and its output is also fed into the fully connected and element-wise sum output layer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"this paper shows that reattention helps alleviate both redundancy and deficiency in attention distributions redundancy reattention increases the kl divergence between adjacent attention blocks indicating that the attention distributions across blocks become more distinct and less redundant deficiency reattention reduces the kl divergence between the normalized attention distribution -lrb- $ e ^ t $ -rrb- and the ideal uniform distribution -lrb- $ -lcb- e ^ t -rcb- ^ * $ -rrb- suggesting that the attention becomes more balanced and closer to the desired distribution however the improvement in redundancy is more pronounced between the first two blocks -lrb- $ e ^ 1 $ to $ e ^ 2 $ -rrb- than the last two blocks -lrb- $ b ^ 2 $ to $ b ^ 3 $ -rrb- this suggests that the first reattention is more effective in capturing word pair similarities using the original word representations in contrast the later reattention might be negatively impacted by the highly non-linear word representations generated in the previous layers\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the training process uses several techniques to handle large vocabulary sizes these include 1 ** token-based batching ** instead of grouping sentences of similar lengths together the training process batches together a fixed number of tokens -lrb- 5120 tokens per batch -rrb- this approach ensures that the model sees a consistent amount of vocabulary regardless of sentence length variation 2 ** shared embedding ** this technique maps both source and target words to the same embedding space effectively reducing the memory footprint needed to store word representations 3 ** positional encoding ** this method injects information about the position of words in a sentence into the model helping it better understand long-range dependencies within the text\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"both tf-idf and bm25 are features used to estimate the relevance of a document to a query however they differ in their underlying calculations tf-idf this feature represents the average product of term frequency -lrb- tf -rrb- and inverse document frequency -lrb- idf -rrb- for each query term within different document sections -lrb- url title content and whole document -rrb- tf measures how often a term appears in a specific document section while idf measures how important that term is across the entire document collection bm25 this feature utilizes the bm25 ranking function which is a probabilistic model that considers term frequency document length and average document length to estimate relevance while it also considers term frequency like tf-idf it incorporates additional factors to improve the weighting scheme\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"model xviii cig-sim & siam-gcn-sim $ ^ -lcb- g -rcb- $ achieves the best performance on the cnss dataset with an f1-score of 90.29 % this model utilizes the following key components 1 cig it directly uses keywords as concepts without community detection 2 sim & siam it employs both term-based similarity encoder -lrb- sim -rrb- and siamese encoder -lrb- siam -rrb- for generating matching vectors on vertices 3 gcn it performs convolution on local matching vectors through gcn layers 4 sim $ ^ -lcb- g -rcb- $ it incorporates additional global features based on the five term-based similarity metrics\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the actions that are most challenging for the network to recognize are those that include moving directions such as person move toward -lrb- home -rrb- person move away -lrb- home -rrb- and vehicle move toward -lrb- person -rrb- the proposed methods distance-based place discretization -lrb- dd -rrb- and topological feature aggregation -lrb- topo-agg -rrb- significantly improve the average precision on almost all action categories especially those that are more challenging and are associated with moving directions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"when the sample size is 2000 the two-phase framework -lrb- msg -rrb- achieves lower discrimination in prediction compared to di both with and without classifier tweaking with classifier tweaking msg achieves a discrimination level of 0.016 ± 5.3e-4 while di shows a significantly higher level of 0.095 ± 1.6e-3 without classifier tweaking msg still demonstrates lower discrimination with 0.067 ± 4.3e-3 compared to di 's 0.095 ± 1.6e-3 this indicates that the two-phase framework is more effective in removing discrimination from predictions than di regardless of whether classifier tweaking is applied\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the multi-hop encoder performs better on babi tasks 3 and 5 because these tasks specifically require inferencing over multiple kb tuples in other words the model needs to hop between different pieces of information in the knowledge base to make the correct inferences and recommendations task 3 involves sorting restaurants by rating and task 5 requires recommending a restaurant based on user preferences both tasks necessitate the model to consider various restaurant attributes and their relationships which the multi-hop encoder facilitates by capturing longer-range dependencies within the knowledge base\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the five deformable cost volumes in devon 's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery this is achieved by using different neighborhood sizes -lrb- k -rrb- and dilation rates -lrb- r -rrb- for each cost volume as shown in table 1 smaller neighborhood sizes and dilation rates result in denser correspondences focusing on finer details and small displacements while larger values capture broader context and larger motions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"table 1 shows that coap has slightly higher reliability -lrb- 99.5 % -rrb- compared to tcplp -lrb- 99.3 % -rrb- while both protocols perform well this difference could be attributed to several factors including retransmission mechanisms coap employs a built-in retransmission mechanism for lost packets while tcplp relies on the underlying network layer for retransmissions this could give coap an edge in recovering lost packets and achieving higher reliability congestion control coap includes mechanisms to adapt to network congestion potentially reducing packet loss and improving reliability packet size coap typically uses smaller packets compared to tcplp smaller packets are less prone to loss in wireless networks potentially contributing to coap 's slightly higher reliability\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"it is difficult to definitively say which system performs better for low-quality captions based solely on the provided data however we can observe some trends 1 when the smt average rank is below 3 the cca average rank is also lower -lrb- 1.64 vs. 1.77 -rrb- 2 when the smt average rank is 3 or higher the cca average rank is significantly higher -lrb- 3.54 vs. 3.46 -rrb- this suggests that cca might perform relatively better for low-quality captions but more data and analysis are needed for a conclusive answer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the semantic self-supervision model performs better on referit -lrb- mask -rrb- compared to referit -lrb- bbox -rrb- because mask-based annotations are considered more precise and accurate for measuring localization performance than bounding boxes masks tightly encompass the specific region referred to by the phrase whereas bounding boxes can include extraneous areas this relates to the difference in performance between visual genome and flickr30k because both visual genome and referit -lrb- mask -rrb- contain phrases that refer to very specific regions or non-salient objects precise localization is crucial for achieving high accuracy on these datasets flickr30k on the other hand annotates all bounding boxes referring to a phrase leading to potentially less precise localization requirements and generally higher performance across methods\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the sdvi loss term 1 & 3 model only uses the pixel reconstruction loss and the inclusive kl divergence loss while the full sdvi model additionally incorporates the pixel prediction loss and the exclusive kl divergence loss according to the passage the exclusive kl divergence term encourages the inference distribution to be more accurate while the pixel prediction loss further improves video quality during inference therefore the absence of these terms in the sdvi loss term 1 & 3 model likely explains its inferior performance compared to the full sdvi model\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"according to the table some common medications used to treat sickle cell anemia include beta-adrenergic agents analgesics -lrb- narcotics and non-narcotics -rrb- nsaids -lrb- cyclooxygenase inhibitor type -rrb- potassium replacement sodium/saline preparations general inhalation agents laxatives and cathartics iv solutions -lrb- dextrose-saline -rrb- antiemetic/antivertigo agents sedative-hypnotics -lrb- non-barbiturate -rrb- glucocorticoids -lrb- orally inhaled -rrb- folic acid preparations analgesic narcotic anesthetic adjunct agents\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the four steps involved in the synonym discovery process are 1 ** entity representation learning ** learn entity representations from the corpus using wembed 2 ** nn search ** perform a nearest neighbor search to find candidate entities for the query entity 3 ** synonym score calculation ** calculate the synonym score between the query entity and each candidate entity using synonym net 4 ** synonym entity discovery ** select the candidate entities with the highest synonym scores as the discovered synonym entities\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"seq2sick differs from existing attack methods in two key aspects 1 search strategy while previous methods primarily rely on greedy search which becomes increasingly inefficient for longer sequences seq2sick employs group lasso regularization and projected gradient descent with gradient regularization this allows for simultaneous searching of all replacement positions leading to improved efficiency 2 targeted attack type existing methods focus on targeting specific classes or binary classifications while seq2sick introduces a novel keyword target type allowing attacks to be directed towards specific keywords within the generated sequence\"\n",
            "Caption may be too long\n",
            "Parsing test captions\n",
            "Threads( StanfordCoreNLP ) [1.722 seconds]\n",
            "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
            "SPICE evaluation took: 4.831 min\n",
            "SPICE: 0.002\n",
            "CIDEr: 0.007\n",
            "SPICE: 0.002\n",
            "BERTScore F1: 0.306\n",
            "Failed parsing: 0\n",
            "Samples evaluated: 666\n",
            "No-answer samples: 3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python /content/MMML-Group-Project/metrics/cider_spice_eval.py --csv /content/MMML-Group-Project/data/blip_results_256.csv --model_name resnet_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l1kpiHBZk_D2",
        "outputId": "15829a6d-ac6e-46bc-8630-87d03d794afa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-26 00:21:48.956360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742948508.988536   20143 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742948509.002218   20143 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-26 00:21:49.059852: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "\n",
            "📄 Evaluating CSV: /content/MMML-Group-Project/data/blip_results_512.csv (model: resnet_mlp)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 18943 tokens at 32396.87 tokens per second.\n",
            "PTBTokenizer tokenized 1662 tokens at 7879.24 tokens per second.\n",
            "setting up scorers...\n",
            "computing Bleu score...\n",
            "{'testlen': 979, 'reflen': 16605, 'guess': [979, 316, 130, 43], 'correct': [82, 1, 0, 0]}\n",
            "ratio: 0.05895814513700337\n",
            "Bleu_1: 0.000\n",
            "Bleu_2: 0.000\n",
            "Bleu_3: 0.000\n",
            "Bleu_4: 0.000\n",
            "computing METEOR score...\n",
            "METEOR: 0.003\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.009\n",
            "computing CIDEr score...\n",
            "CIDEr: 0.006\n",
            "computing SPICE score...\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
            "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Parsing reference captions\n",
            "Initiating Stanford parsing pipeline\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
            "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
            "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
            "done [1.3 sec].\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.9 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [2.5 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.2 sec].\n",
            "Threads( StanfordCoreNLP ) [04:36.471 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"while the model trained on both mot and detection sets shows improved performance in detection and tracking metrics -lrb- ap mota motp -rrb- it also exhibits a higher number of identity switches -lrb- ids -rrb- this can be attributed to the increased diversity of instances introduced by the detection set although the mot set provides a larger number of bounding boxes for training the detection set adds varied examples that may lead to more frequent identity switches during tracking even as it improves the model 's overall performance\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the table and passage show that the translation performance of the br-csgan model generally improves as the number of monte carlo samples -lrb- n -rrb- increases however this improvement plateaus after n reaches a certain point -lrb- around 20 in this case -rrb- there is a trade-off when choosing the value of n because increasing n also increases the computational complexity and training time while a higher n leads to more accurate reward estimations and better performance it also requires more computational resources and longer training times therefore choosing the optimal n involves balancing the desired performance with the available computational resources and time constraints\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the lstnet model has four main types of layers 1 convolutional layer this layer extracts local dependency patterns from the input data 2 recurrent and recurrent-skip layer these layers capture long-term dependencies in the data 3 fully connected and element-wise sum output layer this layer combines the outputs from the convolutional and recurrent layers to produce the final prediction 4 autoregressive layer this layer provides a linear bypass to the non-linear neural network part of the model the convolutional layer receives the input data and passes its output to the recurrent and recurrent-skip layers these layers then pass their output to the fully connected and element-wise sum output layer the autoregressive layer receives the input data directly and its output is also fed into the fully connected and element-wise sum output layer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"this paper shows that reattention helps alleviate both redundancy and deficiency in attention distributions redundancy reattention increases the kl divergence between adjacent attention blocks indicating that the attention distributions across blocks become more distinct and less redundant deficiency reattention reduces the kl divergence between the normalized attention distribution -lrb- $ e ^ t $ -rrb- and the ideal uniform distribution -lrb- $ -lcb- e ^ t -rcb- ^ * $ -rrb- suggesting that the attention becomes more balanced and closer to the desired distribution however the improvement in redundancy is more pronounced between the first two blocks -lrb- $ e ^ 1 $ to $ e ^ 2 $ -rrb- than the last two blocks -lrb- $ b ^ 2 $ to $ b ^ 3 $ -rrb- this suggests that the first reattention is more effective in capturing word pair similarities using the original word representations in contrast the later reattention might be negatively impacted by the highly non-linear word representations generated in the previous layers\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the training process uses several techniques to handle large vocabulary sizes these include 1 ** token-based batching ** instead of grouping sentences of similar lengths together the training process batches together a fixed number of tokens -lrb- 5120 tokens per batch -rrb- this approach ensures that the model sees a consistent amount of vocabulary regardless of sentence length variation 2 ** shared embedding ** this technique maps both source and target words to the same embedding space effectively reducing the memory footprint needed to store word representations 3 ** positional encoding ** this method injects information about the position of words in a sentence into the model helping it better understand long-range dependencies within the text\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"both tf-idf and bm25 are features used to estimate the relevance of a document to a query however they differ in their underlying calculations tf-idf this feature represents the average product of term frequency -lrb- tf -rrb- and inverse document frequency -lrb- idf -rrb- for each query term within different document sections -lrb- url title content and whole document -rrb- tf measures how often a term appears in a specific document section while idf measures how important that term is across the entire document collection bm25 this feature utilizes the bm25 ranking function which is a probabilistic model that considers term frequency document length and average document length to estimate relevance while it also considers term frequency like tf-idf it incorporates additional factors to improve the weighting scheme\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"model xviii cig-sim & siam-gcn-sim $ ^ -lcb- g -rcb- $ achieves the best performance on the cnss dataset with an f1-score of 90.29 % this model utilizes the following key components 1 cig it directly uses keywords as concepts without community detection 2 sim & siam it employs both term-based similarity encoder -lrb- sim -rrb- and siamese encoder -lrb- siam -rrb- for generating matching vectors on vertices 3 gcn it performs convolution on local matching vectors through gcn layers 4 sim $ ^ -lcb- g -rcb- $ it incorporates additional global features based on the five term-based similarity metrics\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the actions that are most challenging for the network to recognize are those that include moving directions such as person move toward -lrb- home -rrb- person move away -lrb- home -rrb- and vehicle move toward -lrb- person -rrb- the proposed methods distance-based place discretization -lrb- dd -rrb- and topological feature aggregation -lrb- topo-agg -rrb- significantly improve the average precision on almost all action categories especially those that are more challenging and are associated with moving directions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"when the sample size is 2000 the two-phase framework -lrb- msg -rrb- achieves lower discrimination in prediction compared to di both with and without classifier tweaking with classifier tweaking msg achieves a discrimination level of 0.016 ± 5.3e-4 while di shows a significantly higher level of 0.095 ± 1.6e-3 without classifier tweaking msg still demonstrates lower discrimination with 0.067 ± 4.3e-3 compared to di 's 0.095 ± 1.6e-3 this indicates that the two-phase framework is more effective in removing discrimination from predictions than di regardless of whether classifier tweaking is applied\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the multi-hop encoder performs better on babi tasks 3 and 5 because these tasks specifically require inferencing over multiple kb tuples in other words the model needs to hop between different pieces of information in the knowledge base to make the correct inferences and recommendations task 3 involves sorting restaurants by rating and task 5 requires recommending a restaurant based on user preferences both tasks necessitate the model to consider various restaurant attributes and their relationships which the multi-hop encoder facilitates by capturing longer-range dependencies within the knowledge base\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the five deformable cost volumes in devon 's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery this is achieved by using different neighborhood sizes -lrb- k -rrb- and dilation rates -lrb- r -rrb- for each cost volume as shown in table 1 smaller neighborhood sizes and dilation rates result in denser correspondences focusing on finer details and small displacements while larger values capture broader context and larger motions\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"table 1 shows that coap has slightly higher reliability -lrb- 99.5 % -rrb- compared to tcplp -lrb- 99.3 % -rrb- while both protocols perform well this difference could be attributed to several factors including retransmission mechanisms coap employs a built-in retransmission mechanism for lost packets while tcplp relies on the underlying network layer for retransmissions this could give coap an edge in recovering lost packets and achieving higher reliability congestion control coap includes mechanisms to adapt to network congestion potentially reducing packet loss and improving reliability packet size coap typically uses smaller packets compared to tcplp smaller packets are less prone to loss in wireless networks potentially contributing to coap 's slightly higher reliability\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"it is difficult to definitively say which system performs better for low-quality captions based solely on the provided data however we can observe some trends 1 when the smt average rank is below 3 the cca average rank is also lower -lrb- 1.64 vs. 1.77 -rrb- 2 when the smt average rank is 3 or higher the cca average rank is significantly higher -lrb- 3.54 vs. 3.46 -rrb- this suggests that cca might perform relatively better for low-quality captions but more data and analysis are needed for a conclusive answer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the semantic self-supervision model performs better on referit -lrb- mask -rrb- compared to referit -lrb- bbox -rrb- because mask-based annotations are considered more precise and accurate for measuring localization performance than bounding boxes masks tightly encompass the specific region referred to by the phrase whereas bounding boxes can include extraneous areas this relates to the difference in performance between visual genome and flickr30k because both visual genome and referit -lrb- mask -rrb- contain phrases that refer to very specific regions or non-salient objects precise localization is crucial for achieving high accuracy on these datasets flickr30k on the other hand annotates all bounding boxes referring to a phrase leading to potentially less precise localization requirements and generally higher performance across methods\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the sdvi loss term 1 & 3 model only uses the pixel reconstruction loss and the inclusive kl divergence loss while the full sdvi model additionally incorporates the pixel prediction loss and the exclusive kl divergence loss according to the passage the exclusive kl divergence term encourages the inference distribution to be more accurate while the pixel prediction loss further improves video quality during inference therefore the absence of these terms in the sdvi loss term 1 & 3 model likely explains its inferior performance compared to the full sdvi model\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"according to the table some common medications used to treat sickle cell anemia include beta-adrenergic agents analgesics -lrb- narcotics and non-narcotics -rrb- nsaids -lrb- cyclooxygenase inhibitor type -rrb- potassium replacement sodium/saline preparations general inhalation agents laxatives and cathartics iv solutions -lrb- dextrose-saline -rrb- antiemetic/antivertigo agents sedative-hypnotics -lrb- non-barbiturate -rrb- glucocorticoids -lrb- orally inhaled -rrb- folic acid preparations analgesic narcotic anesthetic adjunct agents\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the four steps involved in the synonym discovery process are 1 ** entity representation learning ** learn entity representations from the corpus using wembed 2 ** nn search ** perform a nearest neighbor search to find candidate entities for the query entity 3 ** synonym score calculation ** calculate the synonym score between the query entity and each candidate entity using synonym net 4 ** synonym entity discovery ** select the candidate entities with the highest synonym scores as the discovered synonym entities\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"seq2sick differs from existing attack methods in two key aspects 1 search strategy while previous methods primarily rely on greedy search which becomes increasingly inefficient for longer sequences seq2sick employs group lasso regularization and projected gradient descent with gradient regularization this allows for simultaneous searching of all replacement positions leading to improved efficiency 2 targeted attack type existing methods focus on targeting specific classes or binary classifications while seq2sick introduces a novel keyword target type allowing attacks to be directed towards specific keywords within the generated sequence\"\n",
            "Caption may be too long\n",
            "Parsing test captions\n",
            "Threads( StanfordCoreNLP ) \n",
            "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
            "SPICE evaluation took: 4.841 min\n",
            "SPICE: 0.002\n",
            "CIDEr: 0.006\n",
            "SPICE: 0.002\n",
            "BERTScore F1: 0.306\n",
            "Failed parsing: 0\n",
            "Samples evaluated: 666\n",
            "No-answer samples: 3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python /content/MMML-Group-Project/metrics/cider_spice_eval.py --csv /content/MMML-Group-Project/data/blip_results_512.csv --model_name resnet_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "iY9RcnI0ulyu",
        "outputId": "6bfd1786-059a-4823-fe10-28e65016ad52"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set()\n",
        "\n",
        "models = np.array(['Blip2', 'Blip2', 'Blip2'])\n",
        "hyperparameters = np.array(['Original', '256x256', '512x512'])\n",
        "spice = np.array([0.227, 0.226, 0.229])\n",
        "cider = np.array([0.890, 0.863, 0.887])\n",
        "bertscore = np.array([0.503, 0.506, 0.508])\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Model': models,\n",
        "    'Hyperparameters': hyperparameters,\n",
        "    'SPICE': spice,\n",
        "    'CIDEr': cider,\n",
        "    'BERTScore': bertscore\n",
        "})\n",
        "\n",
        "data_melted = data.melt(id_vars=['Model', 'Hyperparameters'],\n",
        "                        value_vars=['SPICE', 'CIDEr', 'BERTScore'],\n",
        "                        var_name='Metric',\n",
        "                        value_name='Score')\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.lineplot(data=data_melted, x='Hyperparameters', y='Score',\n",
        "             hue='Metric', style='Metric', markers=True, dashes=False)\n",
        "\n",
        "plt.title(f'{models[0]} Metric Scores by Hyperparameter Setting')\n",
        "plt.xlabel('Hyperparameters')\n",
        "plt.ylabel('Score')\n",
        "plt.legend(title='Metric')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{models[0]}.png', dpi=600)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "xH1k4I7frpLw",
        "outputId": "7ecac28b-31e4-48d9-ced0-8bea5a5ef41b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "models = np.array(['Blip', 'Blip', 'Blip'])\n",
        "hyperparameters = np.array(['Original', '256x256', '512x512'])\n",
        "spice = np.array([0.002, 0.002, 0.002])\n",
        "cider = np.array([0.006, 0.007, 0.006])\n",
        "bertscore = np.array([0.306, 0.306, 0.306])\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Model': models,\n",
        "    'Hyperparameters': hyperparameters,\n",
        "    'SPICE': spice,\n",
        "    'CIDEr': cider,\n",
        "    'BERTScore': bertscore\n",
        "})\n",
        "\n",
        "data_melted = data.melt(id_vars=['Model', 'Hyperparameters'],\n",
        "                        value_vars=['SPICE', 'CIDEr', 'BERTScore'],\n",
        "                        var_name='Metric',\n",
        "                        value_name='Score')\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.lineplot(data=data_melted, x='Hyperparameters', y='Score',\n",
        "             hue='Metric', style='Metric', markers=True, dashes=False)\n",
        "\n",
        "plt.title(f'{models[0]} Metric Scores by Hyperparameter Setting')\n",
        "plt.xlabel('Hyperparameters')\n",
        "plt.ylabel('Score')\n",
        "plt.legend(title='Metric')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{models[0]}.png', dpi=600)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NVM6cLjn-59"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mmml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
