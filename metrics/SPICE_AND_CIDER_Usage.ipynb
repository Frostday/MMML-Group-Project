{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Usage\n",
        "\n",
        " When output is .csv\n",
        "\n",
        "`python path/to/cider_spice_eval.py --csv path/to/file.csv --model_name your_model_name [--limit N]`\n",
        "\n",
        "\n",
        " When output is .zip\n",
        "\n",
        "`python path/to/cider_spice_eval.py --zip path/to/file.zip --model_name your_model_name [--limit N]`\n",
        "\n",
        "\n",
        "\n",
        "To test all rows, dont pass anything for limit"
      ],
      "metadata": {
        "id": "G-PoUQvbPHpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/MMML-Group-Project/metrics/cider_spice_eval.py --csv /content/MMML-Group-Project/data/blip2_results.csv --model_name resnet_mlp --limit 100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGuDxqByLtYr",
        "outputId": "5d8ff4ec-af29-46a3-df15-8aba4aadda12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-24 03:27:20.095072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742786840.119276    3052 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742786840.126567    3052 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-24 03:27:20.150854: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "\n",
            "ðŸ“„ Evaluating CSV: /content/MMML-Group-Project/data/blip2_results.csv (model: resnet_mlp)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 2738 tokens at 4234.63 tokens per second.\n",
            "PTBTokenizer tokenized 1232 tokens at 3998.48 tokens per second.\n",
            "setting up scorers...\n",
            "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
            "Progress: 384.5M / 384.5M (100.0%)\n",
            "Extracting stanford-corenlp-3.6.0 ...\n",
            "Done.\n",
            "computing Bleu score...\n",
            "{'testlen': 1098, 'reflen': 2382, 'guess': [1098, 1007, 930, 858], 'correct': [553, 321, 216, 144]}\n",
            "ratio: 0.4609571788411163\n",
            "Bleu_1: 0.156\n",
            "Bleu_2: 0.124\n",
            "Bleu_3: 0.104\n",
            "Bleu_4: 0.087\n",
            "computing METEOR score...\n",
            "METEOR: 0.124\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.254\n",
            "computing CIDEr score...\n",
            "CIDEr: 0.807\n",
            "computing SPICE score...\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
            "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Parsing reference captions\n",
            "Initiating Stanford parsing pipeline\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
            "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
            "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
            "done [1.6 sec].\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.7 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.2 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.2 sec].\n",
            "Threads( StanfordCoreNLP ) [01:30.868 minutes]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"it is difficult to definitively say which system performs better for low-quality captions based solely on the provided data however we can observe some trends 1 when the smt average rank is below 3 the cca average rank is also lower -lrb- 1.64 vs. 1.77 -rrb- 2 when the smt average rank is 3 or higher the cca average rank is significantly higher -lrb- 3.54 vs. 3.46 -rrb- this suggests that cca might perform relatively better for low-quality captions but more data and analysis are needed for a conclusive answer\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"seq2sick differs from existing attack methods in two key aspects 1 search strategy while previous methods primarily rely on greedy search which becomes increasingly inefficient for longer sequences seq2sick employs group lasso regularization and projected gradient descent with gradient regularization this allows for simultaneous searching of all replacement positions leading to improved efficiency 2 targeted attack type existing methods focus on targeting specific classes or binary classifications while seq2sick introduces a novel keyword target type allowing attacks to be directed towards specific keywords within the generated sequence\"\n",
            "Caption may be too long\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the five deformable cost volumes in devon 's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery this is achieved by using different neighborhood sizes -lrb- k -rrb- and dilation rates -lrb- r -rrb- for each cost volume as shown in table 1 smaller neighborhood sizes and dilation rates result in denser correspondences focusing on finer details and small displacements while larger values capture broader context and larger motions\"\n",
            "Caption may be too long\n",
            "Parsing test captions\n",
            "Threads( StanfordCoreNLP ) [21.932 seconds]\n",
            "Error: Could not cache item to /usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/cache with key:\n",
            "\"the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task because the number of demonstrations is not available for the push to pose task\"\n",
            "Caption may be too long\n",
            "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
            "SPICE evaluation took: 2.097 min\n",
            "SPICE: 0.247\n",
            "CIDEr: 0.807\n",
            "SPICE: 0.247\n",
            "BERTScore F1: 0.521\n",
            "Failed parsing: 0\n",
            "Samples evaluated: 100\n",
            "No-answer samples: 9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/MMML-Group-Project/metrics/cider_spice_eval.py --zip /content/MMML-Group-Project/data/responses-llava.zip --model_name instruct_blip --limit 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22HzKM_QL0hs",
        "outputId": "c66f2c5a-26dd-455e-dacd-a1f59da8c5c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-24 03:37:01.495793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742787421.525196    5540 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742787421.532729    5540 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-24 03:37:01.558731: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "ðŸ“¦ Evaluating ZIP: /content/MMML-Group-Project/data/responses-llava.zip (model: instruct_blip)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 336 tokens at 2878.60 tokens per second.\n",
            "PTBTokenizer tokenized 405 tokens at 3367.28 tokens per second.\n",
            "setting up scorers...\n",
            "computing Bleu score...\n",
            "{'testlen': 356, 'reflen': 293, 'guess': [356, 346, 336, 326], 'correct': [113, 56, 34, 19]}\n",
            "ratio: 1.2150170648422696\n",
            "Bleu_1: 0.317\n",
            "Bleu_2: 0.227\n",
            "Bleu_3: 0.173\n",
            "Bleu_4: 0.132\n",
            "computing METEOR score...\n",
            "METEOR: 0.185\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.245\n",
            "computing CIDEr score...\n",
            "CIDEr: 0.309\n",
            "computing SPICE score...\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/usr/local/lib/python3.11/dist-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
            "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Parsing reference captions\n",
            "Initiating Stanford parsing pipeline\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
            "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
            "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
            "done [1.8 sec].\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
            "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.0 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [1.1 sec].\n",
            "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
            "Threads( StanfordCoreNLP ) [14.818 seconds]\n",
            "Parsing test captions\n",
            "Threads( StanfordCoreNLP ) [15.689 seconds]\n",
            "Warning: Nashorn engine is planned to be removed from a future JDK release\n",
            "SPICE evaluation took: 41.55 s\n",
            "SPICE: 0.231\n",
            "CIDEr: 0.309\n",
            "SPICE: 0.231\n",
            "BERTScore F1: 0.557\n",
            "Failed parsing: 0\n",
            "Samples evaluated: 10\n",
            "No-answer samples: 0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}